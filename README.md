# Домашнее задание к занятию 5. «Оркестрация кластером Docker контейнеров на примере Docker Swarm»

## ` Дмитрий Климов `

## Задача 1

Дайте письменые ответы на вопросы:

В чём отличие режимов работы сервисов в Docker Swarm-кластере: replication и global?
Какой алгоритм выбора лидера используется в Docker Swarm-кластере?
Что такое Overlay Network?

## Ответ:

## Сравнение режимов работы сервисов в Docker Swarm (Replicated vs Global)
```html
Представим, что Docker Swarm — это наш личный оркестр, которым мы управляете. Режимы работы сервисов определяют, как именно мы хотим, чтобы наши музыканты (контейнеры) играли.

1. Replicated (Реплицированный) — “Мне нужно Х копий”

Это самый частый режим. Мы говорим оркестру: “Мне нужно три копии скрипки (Nginx)”.

Суть: Мы задаём точное число (например, 3, 5, 10). Swarm-менеджер старается запустить ровно это количество экземпляров нашего сервиса, распределяя их по разным сценам (узлам), чтобы повысить надежность.
Что происходит при сбое? Если один из музыкантов (контейнер) заболел или сцена (узел) рухнула, оркестр понимает, что копий стало две, и немедленно находит замену, чтобы снова стало три.
Когда использовать: Для всего, что должно масштабироваться и быть отказоустойчивым – веб-серверы, API-гейтвеи.

2. Global (Глобальный) — “Мне нужен один музыкант на каждой сцене”

Здесь наша команда ведет себя иначе. Мы говорим: “Мне нужен один дежурный скрипач на каждой из доступных сцен (узлов)”.

Суть: Число реплик не фиксируется нами. Swarm гарантирует, что каждый узел, который может запустить наш сервис, получит ровно одну его копию. Если завтра мы добавите новый узел в оркестр, там автоматически появится новый скрипач.
Когда использовать: Для служебных задач, которые должны быть видны и работать локально на каждом физическом сервере. Например, агент мониторинга или система сбора логов. Ему нет смысла запускать 10 копий, если ему нужно просто следить за состоянием своего собственного узла.
Главное отличие: Replicated говорит о количестве экземпляров, а Global — о привязке экземпляра к каждому узлу.
```
## Как Swarm выбирает главного (Лидера)?
```html
Docker Swarm-кластеры построены на принципе консенсуса, чтобы все менеджеры знали одно и то же, даже если что-то пойдет не так. Для этого они используют алгоритм Raft.

Представьте группу высокопоставленных менеджеров (узлов-менеджеров). Среди них должен быть один Главный (Лидер), который принимает все важные решения: “Перезапустить этот сервис”, “Добавить новый узел”.

Raft работает так:

Большинство решает: Чтобы принять решение, нужно согласие большинства (кворума) менеджеров.
Выборы: Менеджеры постоянно “общаются” друг с другом. Если Главный перестает отвечать (пропадает связь), один из других менеджеров говорит: “Кажется, он ушел. Я буду новым кандидатом!”
Голосование: Кандидат стучится ко всем остальным и просит: “Проголосуйте за меня, чтобы я стал новым лидером!”
Новый Главный: Как только кандидат набирает больше половины голосов, он немедленно становится новым Главным, и кластер продолжает работать, не замечая “потери” старого.
Это гарантирует, что кластер не “зависнет” и не начнет принимать противоречивые команды, даже если самый важный узел выйдет из строя.
```
## Что такое Overlay Network (Оверлейная сеть)?
```html
Overlay Network — это как секретный туннель для ваших контейнеров, который позволяет им общаться, даже если они разбросаны по разным серверам (нодам).

Представим, у нас есть три физических сервера (Node A, Node B, Node C), стоящих в разных концах комнаты, и мы хотим, чтобы контейнер на Node A мог легко “поговорить” с контейнером на Node C.

Проблема без оверлея: Нам пришлось бы настраивать сложную маршрутизацию на уровне нашей физической сети, и контейнеры видели бы только “внешний мир” своего сервера.
Решение с Оверлеем (VxLAN): Docker Swarm создает виртуальный слой поверх всего этого.
Когда контейнер на Node A хочет отправить сообщение контейнеру на Node C, Docker “заворачивает” это сообщение в специальный зашифрованный или инкапсулированный пакет (как будто кладет записку в конверт с указанием конечного сервера).
Этот “конверт” отправляется через обычную физическую сеть от Node A к Node C.
Node C “распаковывает” конверт и передает сообщение нужному контейнеру.
```
Итог: Для контейнеров это выглядит так, будто они все сидят в одной большой виртуальной локальной сети. Они могут обращаться друг к другу по именам сервисов (например, app-api), и Docker сам решает, через какой физический узел и туннель доставить этот трафик. Это делает кластер по-настоящему распределенным и простым в управлении.



























